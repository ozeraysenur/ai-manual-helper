import os
from dotenv import load_dotenv
import chromadb
from chromadb.utils import embedding_functions
import google.generativeai as genai

load_dotenv()

COLLECTION_NAME = "manual_chunks"
CHROMA_DB_PATH = "./chroma_db"


def initialize_chromadb():
    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="all-MiniLM-L6-v2"
    )
    return client, embedding_function


def get_or_create_collection(client, embedding_function):
    try:
        collection = client.get_collection(
            name=COLLECTION_NAME,
            embedding_function=embedding_function
        )
        print(f"Found existing collection: {COLLECTION_NAME}")
        print(f"Collection has {collection.count()} documents")
        return collection
    except chromadb.errors.NotFoundError:
        print(f"Collection {COLLECTION_NAME} not found. Creating new one...")
        collection = client.create_collection(
            name=COLLECTION_NAME,
            embedding_function=embedding_function
        )
        print(f"Created new collection: {COLLECTION_NAME}")
        return collection


def check_collection_contents(collection):
    count = collection.count()
    print(f"\nCollection Statistics:")
    print(f"   - Total documents: {count}")
    if count > 0:
        results = collection.get(limit=3)
        print(f"   - Sample document IDs: {results['ids'][:3]}")
        if results['metadatas']:
            print(f"   - Sample metadata: {results['metadatas'][0]}")
    return count > 0


def retrieve_relevant_chunks(query, product=None, top_k=8):  # Daha fazla chunk al
    client, embedding_function = initialize_chromadb()
    collection = get_or_create_collection(client, embedding_function)

    if not check_collection_contents(collection):
        print("Collection is empty! Please run document processing first.")
        return []

    try:
        where_clause = None
        if product:
            where_clause = {"source": {"$eq": product}}
            print(f" Filtering by product: {product}")

        print(f" Searching for: '{query}'")
        results = collection.query(
            query_texts=[query],
            n_results=top_k,
            where=where_clause
        )

        if not results['documents'] or not results['documents'][0]:
            print(" No relevant chunks found for your query.")
            return []

        chunks = []
        for i, (doc, metadata, distance) in enumerate(zip(
                results['documents'][0],
                results['metadatas'][0],
                results['distances'][0]
        )):
            similarity_score = 1 - distance
            chunks.append({
                'content': doc,
                'metadata': metadata,
                'similarity_score': similarity_score,
                'rank': i + 1
            })
            print(
                f" Chunk {i + 1}: Similarity={similarity_score:.3f}, Source={metadata.get('source', 'N/A')}, Page={metadata.get('page', 'N/A')}")

        # YÃ¼ksek benzerlik skoruna sahip chunk'larÄ± filtrele
        high_quality_chunks = [chunk for chunk in chunks if chunk['similarity_score'] > 0.3]

        if not high_quality_chunks:
            print("âš ï¸ No high-quality matches found. Using best available chunks.")
            return chunks[:5]  # En iyi 5'ini al

        return high_quality_chunks[:6]  # En iyi 6'sÄ±nÄ± al

    except Exception as e:
        print(f" Error during retrieval: {str(e)}")
        return []


def generate_gemini_answer(query, chunks):
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        return " Gemini API anahtarÄ± bulunamadÄ±. LÃ¼tfen .env dosyasÄ±na GEMINI_API_KEY=your_key_here ÅŸeklinde ekleyin."

    try:
        genai.configure(api_key=api_key)
        # DoÄŸru model adÄ±nÄ± kullan
        model = genai.GenerativeModel("gemini-1.5-flash")  # gemini-2.5-flash yerine

        # Context'i hazÄ±rla - daha kÄ±sa ve Ã¶z
        context_parts = []
        for i, chunk in enumerate(chunks[:5]):  # En fazla 5 chunk kullan
            source = chunk['metadata'].get('source', 'Bilinmeyen')
            page = chunk['metadata'].get('page', 'N/A')
            content = chunk['content'][:800]  # Her chunk'Ä± kÄ±salt

            context_parts.append(f"[Kaynak {i + 1}: {source} - Sayfa {page}]\n{content}")

        context = "\n\n---\n\n".join(context_parts)

        # Daha kÄ±sa ve etkili prompt
        prompt = f"""Sen bir teknik dokÃ¼mantasyon uzmanÄ±sÄ±n. Sana verilen manual bilgilerini kullanarak kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tla.

KULLANICI SORUSU: {query}

MANUAL BÄ°LGÄ°LERÄ°:
{context}

TALÄ°MATLAR:
1. Soruyu manual bilgilerine gÃ¶re yanÄ±tla
2. EÄŸer tam cevap yoksa, bulunan ilgili bilgileri paylaÅŸ
3. Hangi kaynaktan bilgi aldÄ±ÄŸÄ±nÄ± belirt
4. KullanÄ±cÄ±ya ek yÃ¶nlendirme yap
5. TÃ¼rkÃ§e yanÄ±tla
6. KÄ±sa ve Ã¶z ol (maksimum 500 kelime)

YANIT:"""

        # Gemini'den cevap al
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,
                max_output_tokens=800,  # Daha kÄ±sa yanÄ±tlar
            )
        )

        if response.text:
            return response.text
        else:
            return " Gemini'den yanÄ±t alÄ±namadÄ±. LÃ¼tfen tekrar deneyin."

    except Exception as e:
        error_msg = str(e)
        print(f" Gemini API hatasÄ± detayÄ±: {error_msg}")

        if "API_KEY_INVALID" in error_msg or "invalid" in error_msg.lower():
            return " GeÃ§ersiz API anahtarÄ±. LÃ¼tfen Gemini API anahtarÄ±nÄ±zÄ± kontrol edin."
        elif "QUOTA_EXCEEDED" in error_msg or "quota" in error_msg.lower():
            return " API kotanÄ±z dolmuÅŸ. LÃ¼tfen daha sonra tekrar deneyin."
        elif "SAFETY" in error_msg or "safety" in error_msg.lower():
            return " Ä°Ã§erik gÃ¼venlik politikalarÄ±na takÄ±ldÄ±. LÃ¼tfen sorunuzu yeniden formÃ¼le edin."
        elif "not found" in error_msg.lower() or "model" in error_msg.lower():
            return " Gemini model hatasÄ±. LÃ¼tfen model adÄ±nÄ± kontrol edin (gemini-1.5-flash kullanÄ±lÄ±yor)."
        else:
            return f" Gemini API hatasÄ±: {error_msg}"


def test_gemini_connection():
    """Gemini API baÄŸlantÄ±sÄ±nÄ± test et"""
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print(" GEMINI_API_KEY bulunamadÄ±!")
        return False

    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")  # DoÄŸru model adÄ±
        response = model.generate_content("Test mesajÄ± - kÄ±sa yanÄ±t ver")
        if response.text:
            print(" Gemini API baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±!")
            print(f" Test cevabÄ±: {response.text[:100]}...")
            return True
        else:
            print(" Gemini'den yanÄ±t alÄ±namadÄ±")
            return False
    except Exception as e:
        print(f" Gemini API baÄŸlantÄ± hatasÄ±: {str(e)}")
        return False


def generate_answer(query, chunks):
    if not chunks:
        return """ Sorunuzla ilgili bilgi bulunamadÄ±. 

ğŸ”§ Ã–neriler:
â€¢ Sorunuzu farklÄ± kelimelerle tekrar deneyin
â€¢ Daha genel terimler kullanÄ±n
â€¢ DokÃ¼manlarÄ±n doÄŸru iÅŸlendiÄŸinden emin olun
â€¢ Belirli bir Ã¼rÃ¼n/manual adÄ± belirtin"""

    print(f" Gemini ile yanÄ±t oluÅŸturuluyor...")
    return generate_gemini_answer(query, chunks)


def list_available_manuals():
    client, embedding_function = initialize_chromadb()
    try:
        collection = get_or_create_collection(client, embedding_function)
        all_docs = collection.get()
        if all_docs['metadatas']:
            sources = set()
            for metadata in all_docs['metadatas']:
                if 'source' in metadata:
                    sources.add(metadata['source'])

            if sources:
                print(" Available manuals:")
                for source in sorted(sources):
                    print(f"   ğŸ“– {source}")
                return list(sources)
            else:
                print(" No manuals found in database.")
                return []
        else:
            print(" No manuals found in database.")
            return []
    except chromadb.errors.NotFoundError:
        print(" No collection found. Please process documents first.")
        return []


def main():
    print(" Manual Assistant - Query Handler")
    print("=" * 50)

    # Ä°lk olarak Gemini API baÄŸlantÄ±sÄ±nÄ± test et
    print("ğŸ” Gemini API baÄŸlantÄ±sÄ± test ediliyor...")
    if not test_gemini_connection():
        print("\n Gemini API ile baÄŸlantÄ± kurulamadÄ±!")
        print("\n LÃ¼tfen ÅŸunlarÄ± kontrol edin:")
        print("1. .env dosyasÄ±nda GEMINI_API_KEY doÄŸru tanÄ±mlÄ± mÄ±?")
        print("2. API anahtarÄ±nÄ±z geÃ§erli mi?")
        print("3. Ä°nternet baÄŸlantÄ±nÄ±z var mÄ±?")
        print("4. gemini-1.5-flash modeli kullanÄ±lÄ±yor mu?")
        return

    available_manuals = list_available_manuals()
    if not available_manuals:
        print("\n No processed manuals found!")
        print("Please run document processing first to add manuals to the database.")
        return

    print("\n" + "=" * 50)
    while True:
        query = input("\n Sorunuzu girin (Ã§Ä±kmak iÃ§in 'q'): ").strip()
        if query.lower() in ['q', 'quit', 'exit', 'Ã§Ä±k']:
            print(" GÃ¶rÃ¼ÅŸmek Ã¼zere!")
            break

        if not query:
            print(" LÃ¼tfen geÃ§erli bir soru girin.")
            continue

        print(f"\nğŸ” Ä°ÅŸleniyor: '{query}'")
        product = input(" (Ä°steÄŸe baÄŸlÄ±) Belirli bir manual/Ã¼rÃ¼n adÄ± (boÅŸ bÄ±rakabilirsiniz): ").strip()

        if product and product not in available_manuals:
            print(f"âš ï¸  Manual '{product}' bulunamadÄ±. TÃ¼m manuallerde aranacak.")
            product = None

        print(f"\n Ä°lgili bilgiler aranÄ±yor...")
        chunks = retrieve_relevant_chunks(query, product=product)

        if chunks:
            print(f"\n {len(chunks)} adet ilgili bilgi bulundu")
            print(f"\nCevap oluÅŸturuluyor...")
            answer = generate_answer(query, chunks)
            print("\n" + "=" * 80)
            print("ğŸ“‹ CEVAP:")
            print("=" * 80)
            print(answer)
            print("=" * 80)
        else:
            print("\nÄ°lgili bilgi bulunamadÄ±.")
            print("\nÃ–neriler:")
            print("â€¢ Sorunuzu farklÄ± kelimelerle tekrar deneyin")
            print("â€¢ Daha genel terimler kullanÄ±n")
            print("â€¢ Belirli bir Ã¼rÃ¼n/konu belirtin")


if __name__ == "__main__":
    main()